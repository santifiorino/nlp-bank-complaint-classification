{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('wells_fargo.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The average length of the complaints is:\", int(df['Consumer complaint narrative'].str.len().mean()), \"characters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower case\n",
    "df['Consumer complaint narrative'] = df['Consumer complaint narrative'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non-alphanumeric characters\n",
    "import re\n",
    "df['Consumer complaint narrative'] = df['Consumer complaint narrative'].apply(lambda x: re.sub(r'[^a-zA-Z0-9\\s]', '', x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet') # for lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "df['Consumer complaint narrative'] = df['Consumer complaint narrative'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['Consumer complaint narrative'] = df['Consumer complaint narrative'].apply(lambda x: lemmatizer.lemmatize(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The average length of the complaints is:\", int(df['Consumer complaint narrative'].str.len().mean()), \"characters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute embeddings (tarda 3 min)\n",
    "df['embedding'] = df['Consumer complaint narrative'].apply(lambda x: model.encode(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"embedding\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def reduce_dimensions(embeddings, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(embeddings)\n",
    "    return pca.transform(embeddings).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = np.array(df['embedding'].to_list())\n",
    "pca_components = [32, 64, 128, 256]\n",
    "for i in pca_components:\n",
    "    df['embedding_pca_' + str(i)] = reduce_dimensions(all_embeddings, i)\n",
    "    df['embedding_pca_' + str(i)] = df['embedding_pca_' + str(i)].apply(lambda x: np.array(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = df.sample(frac=1, random_state=123) # shuffle\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "k_range = list(range(1, 51))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "for i in pca_components:\n",
    "    grid = GridSearchCV(KNeighborsClassifier(metric='cosine'), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid.fit(list(train_df[f'embedding_pca_{i}']), train_df['Product'])\n",
    "    print(f\"Best accuracy for {i} components: {grid.best_score_}\")\n",
    "    plt.plot(k_range, grid.cv_results_['mean_test_score'])\n",
    "grid.fit(list(train_df['embedding']), train_df['Product'])\n",
    "print(f\"Best accuracy for full embedding: {grid.best_score_}\")\n",
    "plt.plot(k_range, grid.cv_results_['mean_test_score'], color='black')\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated Accuracy')\n",
    "plt.legend(pca_components + ['full embedding'])\n",
    "# make plot bigger and save it with 300 dpi\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the best model\n",
    "knn = KNeighborsClassifier(n_neighbors=15, metric='cosine')\n",
    "knn.fit(list(train_df['embedding_pca_128']), train_df['Product'])\n",
    "test_df[\"knn_pred\"] = knn.predict(list(test_df['embedding_pca_128']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metrics\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_df['Product'], test_df['knn_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "cm = confusion_matrix(test_df['Product'], test_df['knn_pred'])\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=df['Product'].unique(), yticklabels=df['Product'].unique())\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001]}\n",
    "grid = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "for i in pca_components:\n",
    "    grid.fit(list(train_df[f'embedding_pca_{i}']), train_df['Product'])\n",
    "    print(f\"Best accuracy for {i} components: {grid.best_score_}\")\n",
    "grid.fit(list(train_df['embedding']), train_df['Product'])\n",
    "print(f\"Best accuracy for full embedding: {grid.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the best model\n",
    "svm = SVC(C=grid.best_params_['C'], gamma=grid.best_params_['gamma'])\n",
    "svm.fit(list(train_df['embedding']), train_df['Product'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "test_df[\"svm_pred\"] = svm.predict(list(test_df['embedding']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metrics\n",
    "print(classification_report(test_df['Product'], test_df['svm_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(test_df['Product'], test_df['svm_pred'])\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=df['Product'].unique(), yticklabels=df['Product'].unique())\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search\n",
    "param_grid = {'C': [0.1, 1, 10, 100]}\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "for i in pca_components:\n",
    "    grid.fit(list(train_df[f'embedding_pca_{i}']), train_df['Product'])\n",
    "    print(f\"Best accuracy for {i} components: {grid.best_score_}\")\n",
    "grid.fit(list(train_df['embedding']), train_df['Product'])\n",
    "print(f\"Best accuracy for full embedding: {grid.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the best model\n",
    "lr = LogisticRegression(C=1)\n",
    "lr.fit(list(train_df['embedding_pca_256']), train_df['Product'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "test_df[\"lr_pred\"] = lr.predict(list(test_df['embedding_pca_256']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metrics\n",
    "print(classification_report(test_df['Product'], test_df['lr_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(test_df['Product'], test_df['lr_pred'])\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=df['Product'].unique(), yticklabels=df['Product'].unique())\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
